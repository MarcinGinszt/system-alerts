# PROMETHEUS RULES
# DO NOT REMOVE line above, used in `pre-commit` hook

groups:
  - name: NamespaceSync
    rules:
      - alert: KubeApplierErrors
        expr: kube_applier_last_run_success != 1
        for: 1h10m
        annotations:
          summary: "kube-applier encountered errors while applying {{ $labels.namespace }}"
          impact: Some manifest won't be automatically deployed.
          action: "Check the web UI / logs for errors."
          link: https://kube-applier-system.{{$labels.uw_environment}}.{{$labels.cloud_provider}}.uw.systems/
      - alert: ArgoCDApplicationNotSynced
        expr: argocd_app_info{sync_status!="Synced"} == 1
        for: 24h
        annotations:
          summary: "ArgoCD application {{$labels.name}} is not synced for last 24h"
          impact: "Some manifests won't be automatically deployed."
          action: "Check the web UI / logs for errors."
          link: https://argocd-system.{{$labels.uw_environment}}.{{$labels.cloud_provider}}.uw.systems/applications/{{$labels.namespace}}/{{$labels.module}}
      - alert: ArgoCDApplicationSyncFailure
        expr: increase(argocd_app_sync_total{phase=~"Error|Failed"}[1h]) > 0
        annotations:
          summary: "ArgoCD application {{$labels.name}} Sync failed"
          impact: "Some manifests won't be automatically deployed."
          action: "Check the web UI / logs for errors."
          link: https://argocd-system.{{$labels.uw_environment}}.{{$labels.cloud_provider}}.uw.systems/applications/{{$labels.namespace}}/{{$labels.module}}
  - name: MissingReplicas
    rules:
      - alert: DeploymentMissingReplicas
        expr: kube_deployment_status_replicas_available != kube_deployment_status_replicas
        for: 15m
        annotations:
          summary: "Deployment {{$labels.namespace}}/{{$labels.deployment}} has missing replicas for 15m"
          impact: "Workload may be unavailable or have lost high availability"
          action: "Check why some replicas are not healthy"
          command: "kubectl --context $ENVIRONMENT-$PROVIDER --namespace {{ $labels.namespace }} describe deployment {{ $labels.deployment }}"
      - alert: StatefulsetMissingReplicas
        expr: kube_statefulset_status_replicas_ready != kube_statefulset_status_replicas
        for: 15m
        annotations:
          summary: "Statefulset {{$labels.namespace}}/{{$labels.statefulset}} has missing replicas for 15m"
          impact: "Workload may be unavailable or have lost high availability"
          action: "Check why some replicas are not healthy"
          command: "kubectl --context $ENVIRONMENT-$PROVIDER --namespace {{ $labels.namespace }} describe statefulset {{ $labels.statefulset }}"
      - alert: DaemonsetMissingReplicas
        expr: kube_daemonset_status_number_ready != kube_daemonset_status_desired_number_scheduled
        for: 15m
        annotations:
          summary: "Daemonset {{$labels.namespace}}/{{$labels.daemonset}} has missing replicas for 15m"
          impact: "Workload unavailable on some nodes"
          action: "Check why some replicas are not healthy"
          command: "kubectl --context $ENVIRONMENT-$PROVIDER --namespace {{ $labels.namespace }} describe daemonset {{ $labels.daemonset }}"
      - alert: DeploymentMissingAllReplicas
        expr: kube_deployment_status_replicas_available == 0 and kube_deployment_status_replicas != 0
        for: 5m
        annotations:
          summary: "Deployment {{$labels.namespace}}/{{$labels.deployment}} has been missing all of its replicas for 5 minutes."
          impact: "Workload is down"
          action: "Check why all replicas are missing"
          command: "kubectl --context $ENVIRONMENT-$PROVIDER --namespace {{ $labels.namespace }} describe deployment {{ $labels.deployment }}"
      - alert: StatefulsetMissingAllReplicas
        expr: kube_statefulset_status_replicas_ready == 0 and kube_statefulset_status_replicas != 0
        for: 5m
        annotations:
          summary: "Statefulset {{$labels.namespace}}/{{$labels.statefulset}} has been missing all of its replicas for 5 minutes."
          impact: "Workload is down"
          action: "Check why all replicas are missing"
          command: "kubectl --context $ENVIRONMENT-$PROVIDER --namespace {{ $labels.namespace }} describe statefulset {{ $labels.statefulset }}"
      - alert: DaemonsetMissingAllReplicas
        expr: kube_daemonset_status_number_ready == 0 and kube_daemonset_status_desired_number_scheduled != 0
        for: 5m
        annotations:
          summary: "Daemonset {{$labels.namespace}}/{{$labels.daemonset}} has been missing all of its replicas for 5 minutes."
          impact: "Workload is down"
          action: "Check why all replicas are missing"
          command: "kubectl --context $ENVIRONMENT-$PROVIDER --namespace {{ $labels.namespace }} describe daemonset {{ $labels.daemonset }}"
  - name: Container
    rules:
      - alert: ContainerRestartingOften
        expr: increase(kube_pod_container_status_restarts_total[10m]) > 3
        annotations:
          summary: "Container {{$labels.namespace}}/{{$labels.pod}}/{{$labels.container}} has restarted more than 3 times in the last 10m"
          impact: "Container may be crashlooping and not working as expected"
          action: "Check pod status and container logs to figure out if there's a problem"
          command: "kubectl --context $ENVIRONMENT-$PROVIDER --namespace {{ $labels.namespace }} describe pod {{ $labels.pod }}"
          logs: "https://grafana.$ENVIRONMENT.aws.uw.systems/explore?orgId=1&left=%7B%22datasource%22%3A%22P8E80F9AEF21F6940%22%2C%22queries%22%3A%5B%7B%22refId%22%3A%22A%22%2C%22expr%22%3A%22%7Bkubernetes_cluster%3D%5C%22$ENVIRONMENT-$PROVIDER%5C%22%2C+kubernetes_namespace%3D%5C%22{{ $labels.namespace }}%5C%22%2C+app_kubernetes_io_name%3D%5C%{{ $labels.label_app_kubernetes_io_name }}%5C%22%7D%22%2C%22queryType%22%3A%22range%22%2C%22datasource%22%3A%7B%22type%22%3A%22loki%22%2C%22uid%22%3A%22P8E80F9AEF21F6940%22%7D%2C%22editorMode%22%3A%22code%22%7D%5D%2C%22range%22%3A%7B%22from%22%3A%22now-1h%22%2C%22to%22%3A%22now%22%7D%7D"
      - alert: ContainerCpuThrottled
        # https://github.com/kubernetes-monitoring/kubernetes-mixin/issues/108#issuecomment-432796867
        expr: sum(increase(container_cpu_cfs_throttled_periods_total[5m])) by (container, pod, namespace) / sum(increase(container_cpu_cfs_periods_total[5m])) by (container, pod, namespace) > 0.95
        for: 15m
        annotations:
          summary: "Container {{$labels.namespace}}/{{$labels.pod}}/{{$labels.container}} is being CPU throttled."
          impact: "Container might take longer than normal to respond to requests."
          action: "Investigate CPU consumption and adjust pods resources if needed."
          dashboard: "https://grafana.$ENVIRONMENT.$PROVIDER.uw.systems/d/VAE0wIcik/kubernetes-pod-resources?orgId=1&refresh=1m&from=now-12h&to=now&var-instance=All&var-namespace={{ $labels.namespace }}"
  - name: Storage
    rules:
      - alert: DiskFillingUpin72h
        expr: predict_linear(kubelet_volume_stats_available_bytes[1h], 72 * 3600) < 0 and kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes > 0.2
        for: 5m
        annotations:
          summary: "Volume {{$labels.namespace}}/{{$labels.persistentvolumeclaim}} will fill up in 72h"
          impact: "Exhausting available disk space will most likely result in service disruption"
          action: "Investigate disk usage and adjust volume size if necessary."
          dashboard: "https://grafana.$ENVIRONMENT.$PROVIDER.uw.systems/d/919b92a8e8041bd567af9edab12c840c/kubernetes-persistent-volumes?orgId=1&refresh=10s&var-datasource=default&var-cluster=&var-namespace={{ $labels.namespace }}&var-volume={{ $labels.persistentvolumeclaim }}"
